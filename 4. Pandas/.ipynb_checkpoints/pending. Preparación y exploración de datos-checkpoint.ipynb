{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparación y exploración de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez conocidas las estructuras de datos de pandas, las operaciones básicas que se pueden realizar sobre las mismas y el modo en el que realizar la carga y almacenamiento de dichas estructuras en discos, vamos a centrarnos en aquellas funcionalidades ofrecidas por pandas que están más orientadas al tratamiento y análisis de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestión de datos en blanco (<i>missing values</i>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la mayoría de los ficheros utilizados como fuente de datos, es muy común la existencia de valores nulos (en blanco, <i>missing</i>...). Estos \"huecos\" en la información suelen ser muy problemáticos ya que tiene un impacto importante a la hora de realizar cualquier tipo de cálculo numérico y son difícilmente interpretables.<br/>\n",
    "Uno de los objetivos de pandas en su construcción fue facilitar el tratamiento de este tipo de datos no existentes ofreciendo múltiples funciones que permiten llevar a cabo tanto su detección, como su eliminación o imputación..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detección de <i>missing values</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas ofrece principalmente dos funciones para manejar la detección de valores nulos.<br/>\n",
    "<ul>\n",
    "<li><b>isnull:</b> Que devuelve una Serie o DataFrame booleano indicando qué elemetos son NaN o None.</li>\n",
    "<li><b>notnull:</b> Que devuelve el inverso del anterior.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro = pd.read_table('datos/catastro.tsv', nrows=10)\n",
    "catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de valores nulos\n",
    "catastro.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de valores no nulos\n",
    "catastro.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminación de registros con <i>missing values</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque SIEMPRE conviene hacer un estudio cuidadoso del por qué y la casuística de los valores nulos, uno de los posibles tratamientos a aplicar es su eliminación directa del set de datos. Pandas, nos ofrece el método <b>dropna</b> para llevar a cabo esta tarea. Los parámetros de este método son:<br/>\n",
    "<ul>\n",
    "<li><b>axis:</b> Selección de eje sobre el que realizar la eliminación.</li>\n",
    "<li><b>how:</b> Tomará posibles valores 'any' y 'all' e indica si se debe eliminar la fila o columna cuando haya uno o más valores NaN o cuando todos los valores sean NaN.</li>\n",
    "<li><b>thresh:</b> Permite indicar, el número de observaciones no nulas que se deben tener para no realizar el borrado.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro = pd.read_table('datos/catastro.tsv', nrows=10)\n",
    "catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de filas con al menos 1 NA\n",
    "catastro.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de columnas con al menos 1 NA\n",
    "catastro.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de filas con 2 o más NA\n",
    "catastro.dropna(thresh=len(catastro.columns)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputación de registros con <i>missing values</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existirán casos en los que no se desee (o no se pueda) eliminar los registros con valores nulos (p.e. podrían suponer un porcentaje demasiado elevado de nuestro set de datos). En estos casos, habrá que realizar una imputación de los mismos a un valor preestablecidor.<br/>\n",
    "Pandas pone a nuestra disposición el método <b>fillna</b>, que cuenta, entre otros, con los siguientes parámetros:<br/>\n",
    "<ul>\n",
    "<li><b>axis:</b> Que decide si aplicará el criterio de relleno por filas o columnas.</li>\n",
    "<li><b>value:</b> Que rellena los valores nulos a un valor fijo.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro = pd.read_table('datos/catastro.tsv', nrows=10)\n",
    "catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de valores a 0\n",
    "catastro.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de datos y estadísticos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que NumPy, pandas ofrece un conjunto amplio de funciones para llevar a cabo un análisis estadístico de datos.  Las más relevantes serían:<br/>\n",
    "<ul>\n",
    "<li><b>describe:</b> Presenta un conjunto con las estadísticas básicas más comunes calculadas sobre todas las columnas de la estructura. Equivalente a la función <i>summary</i> de R.</li>\n",
    "<li><b>count:</b> Número de elementos no nulos.</li>\n",
    "<li><b>min, max:</b> Valor mínimo y máximo.</li>\n",
    "<li><b>argmin, argmax, idxmax, idxmin:</b> Posiciones con valor mínimo y máximo.</li>\n",
    "<li><b>quantile:</b> Cuantil calculado.</li>\n",
    "<li><b>sum:</b> Suma de elementos.</li>\n",
    "<li><b>mean:</b> Media aritmética de los elementos.</li>\n",
    "<li><b>median:</b> Mediana de los elementos.</li>\n",
    "<li><b>std:</b> Desviación estándar de los elementos.</li>\n",
    "<li><b>var:</b> Varianza de los elementos.</li>\n",
    "<li><b>cumsum:</b> Suma acumulada de los elementos.</li>\n",
    "<li><b>cumprod:</b> Producto acumulado de los elementos.</li>\n",
    "</ul>\n",
    "\n",
    "La mayor parte de estos métodos, podrán recibir 3 parámetros:\n",
    "<ul>\n",
    "<li><b>axis:</b> Que indica si realizar el cálculo por filas o columnas.</li>\n",
    "<li><b>skipna:</b> Que indica si se deben ignorar o no los valores NaN a la hora de realizar los cálculos.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro = pd.read_table('datos/catastro.tsv', nrows=10)\n",
    "catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticos básicos sobre el data set\n",
    "catastro.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma por columnas\n",
    "catastro.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suma por filas ignorando NA\n",
    "catastro.sum(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catastro.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementos únicos y frecuencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>unique</b>: Que nos devuelve un array con el conjunto de elementos únicos de una Serie.</li>\n",
    "<li><b>value_counts</b>: Que realiza un cálculo de frecuencias sobre los elementos únicos de una Serie.</li>\n",
    "<li><b>isin:</b> Que nos permite chequear si un conjunto de valores se encuentra en una Serie.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catastro = pd.read_table('datos/catastro.tsv')\n",
    "catastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de de barrios\n",
    "catastro.barrio.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla de frecuencias de distritos\n",
    "catastro.distrito.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequeo de existencia de distritos\n",
    "catastro[catastro['distrito'].isin(['Centro', 'Latina'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de funciones sobre estructuras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Al igual que en R tenemos la familia de funciones <i>apply</i>, pandas pone a nuestra disposición un conjunto de funciones que nos permiten aplicar operaciones elemento a elemento (o fila a fila, o columna a columna) en sus estructuras de datos. En concreto disponemos de tres funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación de funciones elemento a elemento sobre Series - Función map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = pd.Series([1, 2, 3, 4, 5, 6])\n",
    "serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_par(elemento):\n",
    "    if elemento % 2 == 0:\n",
    "        return 'Par: ' + str(elemento)\n",
    "    else:\n",
    "        return 'Impar: ' + str(elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función elemento a elemento sobre Serie\n",
    "serie.map(es_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación de funciones elemento a elemento sobre DataFrames - Función applymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(np.arange(16).reshape(4, 4))\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_par(elemento):\n",
    "    if elemento % 2 == 0:\n",
    "        return 'Par: ' + str(elemento)\n",
    "    else:\n",
    "        return 'Impar: ' + str(elemento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función elemento a elemento sobre DataFrame\n",
    "dataframe.applymap(es_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación de funciones fila a fila o columna a columna sobre DataFrames - Función apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(np.arange(16).reshape(4, 4))\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_suma_par(elemento):\n",
    "    if np.sum(elemento) % 2 == 0:\n",
    "        return 'Suma par: ' + str(np.sum(elemento))\n",
    "    else:\n",
    "        return 'Suma impar: ' + str(np.sum(elemento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función por columnas sobre DataFrame\n",
    "dataframe.loc[:, 0:1].apply(es_suma_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de función por filas sobre DataFrames\n",
    "dataframe.apply(es_suma_par, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusión de estructuras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería pandas nos ofrece, principalmente, dos formas de fusionar estructuras de datos: realizando cruces entre ellos (mediante las claves coincidentes de sus índices) o concatenando sus contenidos (bien por filas o columnas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función merge - JOIN de estructuras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas = pd.DataFrame(\n",
    "            {'Año':[2014, 2014, 2013, 2013], \n",
    "             'Valoración':[6, None, 8.75, None],\n",
    "             'Presupuesto':[160, 250, 100, None],\n",
    "             'Director':['Gareth Edwards','Peter Jackson',  'Martin Scorsese', 'Alfonso Cuarón'],\n",
    "             'Título':['Godzilla', 'El Hobbit III', 'El lobo de Wall Street', 'Gravity']}\n",
    ")\n",
    "peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directores = pd.DataFrame(\n",
    "            {'Director':['Gareth Edwards', 'Martin Scorsese', 'Pedro Almodovar'],\n",
    "             'AñoNacimiento':[1975, 1942, 1949],\n",
    "             'Nacionalidad': ['England', 'USA', 'Spain']\n",
    "             }\n",
    ")\n",
    "directores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(peliculas, directores[['Director', 'AñoNacimiento']], on = ['Director'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función busca, por defecto, aquellas claves de columnas que coinciden y realiza el cruce, eliminando del resultado aquellas filas para las que el cruce no es posible.<br/>\n",
    "\n",
    "También podemos especificar, explícitamente, el conjunto de columnas a utilizar en el cruce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directores.columns = ['Nombre', 'Nacimiento', 'Nacionalidad']\n",
    "pd.merge(peliculas, directores, left_on='Director', right_on='Nombre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, al igual que ocurre en os JOIN de SQL, podemos especificar el modo de cruce a aplicar, haciendo que las filas de la estructura de la izquierda, derecha o ambas que no coincidan se mantengan en el resultado, estableciendo valores NaN en aquellos elementos para los que no exista información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(peliculas, directores, left_on='Director', right_on='Nombre', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(peliculas, directores, left_on='Director', right_on='Nombre', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(peliculas, directores, left_on='Director', right_on='Nombre', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, en el caso de que tengamos columnas duplicadas en los dos DataFrames que se van a unir, pandas se encargará automáticamente de incluir un sufijo que permita desambiguar (_x, _y, por defecto). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas = pd.DataFrame(\n",
    "            {'Año':[2014, 2014, 2013, 2013], \n",
    "             'Valoración':[6, None, 8.75, None],\n",
    "             'Presupuesto':[160, 250, 100, None],\n",
    "             'Director':['Peter Jackson', 'Gareth Edwards', 'Martin Scorsese', 'Alfonso Cuarón'],\n",
    "             'Título':['Godzilla', 'El Hobbit III', 'El lobo de Wall Street', 'Gravity']}\n",
    ")\n",
    "directores = pd.DataFrame(\n",
    "            {'Director':['Gareth Edwards', 'Martin Scorsese', 'Pedro Almodovar'],\n",
    "             'AñoNacimiento':[1975, 1942, 1949],\n",
    "             'Nacionalidad': ['England', 'USA', 'Spain'],\n",
    "             'Valoración':[6, 7, 8]\n",
    "             }\n",
    ")\n",
    "pd.merge(peliculas, directores, left_on='Director', right_on='Director')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos modificar estos sufijos, podemos hacer uso del parámetro suffixes que recibe una tupla con los sufijos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(peliculas, directores, left_on='Director', right_on='Director', suffixes=('_peli', '_dire'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función nos permite fusionar estructuras sin realizar ningún tipo de cruce entre ellas, sino \"colocándolas\" juntas para la creación de una estructura mayor. Podemos hacerlo tanto en filas como en columnas. Por defecto, se concatenan filas y se mantienen las columnas de ambas estructuras aunque no coincidan en clave, dejando a NaN los elementos que no existan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas = pd.DataFrame(\n",
    "            {'Año':[2014, 2014, 2013, 2013], \n",
    "             'Valoración':[6, None, 8.75, None],\n",
    "             'Presupuesto':[160, 250, 100, None],\n",
    "             'Director':['Gareth Edwards','Peter Jackson', 'Martin Scorsese', 'Alfonso Cuarón']},\n",
    "            index = ['Godzilla', 'El Hobbit III', 'El lobo de Wall Street', 'Gravity']\n",
    ")\n",
    "peliculas2 = pd.DataFrame(\n",
    "            {'Año':[2014, 2014], \n",
    "             'Valoración':[7.3, 6.3],\n",
    "             'Director':['Evan Goldberg', ' Rupert Wyatt']},\n",
    "            index = ['La entrevista', 'El jugador']\n",
    ")\n",
    "peliculas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([peliculas, peliculas2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos concatenar por columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas3 = pd.DataFrame(\n",
    "            {'Recaudación':[525, 722, 392]},\n",
    "            index = ['Godzilla', 'El Hobbit III', 'El lobo de Wall Street']\n",
    ")\n",
    "pd.concat([peliculas, peliculas3],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque es un funcionamiento más propio de la función merge, pandas nos permite eliminar del resultado aquellas combinaciones para las que no existen datos en alguna de las dos estructuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([peliculas, peliculas3],axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, puede ser útil identificar en la estructura resultante el origen de cada una de las filas para posterior análisis. La función concat incluye un parámetro <b>keys</b> que podemos utilizar para añadir una clave a cada uno de las estructuras origen, que se convertirá en el nivel más agregado de un índice jerárquico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([peliculas, peliculas2], keys=['dataset1','dataset2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones de agrupación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La librería pandas también incluye la posibiilidad de hacer agrupación de resultados y operaciones sobre los grupos (al estilo de las sentencias GROUP BY de SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agrupado = peliculas.groupby('Año')\n",
    "type(agrupado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una agrupación no es un objeto \"imprimible\", es una representación interna del conjunto de registros que pertenecen a cada grupo y sólo tiene sentido si, posteriormente, se va a aplicar alguna operación sobre dichos grupos. Hay que tener en cuenta que no todas las operaciones son aplicacables sobre todos los tipos de columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media por grupo\n",
    "agrupado.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteo de valores no nulos por grupo\n",
    "agrupado.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque con estos datos quizá no tenga tanto sentido, podemos realizar la agrupación por múltiples claves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peliculas.groupby(['Año', 'Director']).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
